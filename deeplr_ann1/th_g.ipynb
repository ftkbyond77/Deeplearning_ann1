{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\BM MONEY\\miniconda3\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Looks like you're using an outdated `kagglehub` version, please consider updating (latest version: 0.3.8)\n",
      "Path to dataset files: C:\\Users\\BM MONEY\\.cache\\kagglehub\\datasets\\uciml\\glass\\versions\\1\n"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"uciml/glass\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_67c50_row0_col0, #T_67c50_row0_col2, #T_67c50_row0_col6, #T_67c50_row1_col1, #T_67c50_row2_col3, #T_67c50_row3_col5, #T_67c50_row4_col4 {\n",
       "  background-color: #08306b;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_67c50_row0_col1 {\n",
       "  background-color: #4090c5;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_67c50_row0_col3, #T_67c50_row0_col4, #T_67c50_row0_col5, #T_67c50_row0_col7, #T_67c50_row0_col8, #T_67c50_row0_col9, #T_67c50_row1_col7, #T_67c50_row1_col8, #T_67c50_row1_col9, #T_67c50_row2_col0, #T_67c50_row2_col2, #T_67c50_row2_col6, #T_67c50_row2_col7, #T_67c50_row2_col8, #T_67c50_row2_col9, #T_67c50_row3_col1, #T_67c50_row3_col7, #T_67c50_row3_col8, #T_67c50_row3_col9, #T_67c50_row4_col7, #T_67c50_row4_col8, #T_67c50_row4_col9 {\n",
       "  background-color: #f7fbff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_67c50_row1_col0 {\n",
       "  background-color: #b8d5ea;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_67c50_row1_col2, #T_67c50_row1_col6 {\n",
       "  background-color: #edf4fc;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_67c50_row1_col3 {\n",
       "  background-color: #4d99ca;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_67c50_row1_col4 {\n",
       "  background-color: #2575b7;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_67c50_row1_col5 {\n",
       "  background-color: #125ea6;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_67c50_row2_col1 {\n",
       "  background-color: #77b5d9;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_67c50_row2_col4 {\n",
       "  background-color: #084285;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_67c50_row2_col5 {\n",
       "  background-color: #3c8cc3;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_67c50_row3_col0 {\n",
       "  background-color: #b4d3e9;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_67c50_row3_col2 {\n",
       "  background-color: #d9e8f5;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_67c50_row3_col3 {\n",
       "  background-color: #87bddc;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_67c50_row3_col4 {\n",
       "  background-color: #3e8ec4;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_67c50_row3_col6 {\n",
       "  background-color: #7db8da;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_67c50_row4_col0 {\n",
       "  background-color: #c4daee;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_67c50_row4_col1 {\n",
       "  background-color: #e6f0f9;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_67c50_row4_col2 {\n",
       "  background-color: #e8f1fa;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_67c50_row4_col3 {\n",
       "  background-color: #b0d2e7;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_67c50_row4_col5 {\n",
       "  background-color: #083a7a;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_67c50_row4_col6 {\n",
       "  background-color: #b7d4ea;\n",
       "  color: #000000;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_67c50\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_67c50_level0_col0\" class=\"col_heading level0 col0\" >RI</th>\n",
       "      <th id=\"T_67c50_level0_col1\" class=\"col_heading level0 col1\" >Na</th>\n",
       "      <th id=\"T_67c50_level0_col2\" class=\"col_heading level0 col2\" >Mg</th>\n",
       "      <th id=\"T_67c50_level0_col3\" class=\"col_heading level0 col3\" >Al</th>\n",
       "      <th id=\"T_67c50_level0_col4\" class=\"col_heading level0 col4\" >Si</th>\n",
       "      <th id=\"T_67c50_level0_col5\" class=\"col_heading level0 col5\" >K</th>\n",
       "      <th id=\"T_67c50_level0_col6\" class=\"col_heading level0 col6\" >Ca</th>\n",
       "      <th id=\"T_67c50_level0_col7\" class=\"col_heading level0 col7\" >Ba</th>\n",
       "      <th id=\"T_67c50_level0_col8\" class=\"col_heading level0 col8\" >Fe</th>\n",
       "      <th id=\"T_67c50_level0_col9\" class=\"col_heading level0 col9\" >Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_67c50_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_67c50_row0_col0\" class=\"data row0 col0\" >1.521010</td>\n",
       "      <td id=\"T_67c50_row0_col1\" class=\"data row0 col1\" >13.640000</td>\n",
       "      <td id=\"T_67c50_row0_col2\" class=\"data row0 col2\" >4.490000</td>\n",
       "      <td id=\"T_67c50_row0_col3\" class=\"data row0 col3\" >1.100000</td>\n",
       "      <td id=\"T_67c50_row0_col4\" class=\"data row0 col4\" >71.780000</td>\n",
       "      <td id=\"T_67c50_row0_col5\" class=\"data row0 col5\" >0.060000</td>\n",
       "      <td id=\"T_67c50_row0_col6\" class=\"data row0 col6\" >8.750000</td>\n",
       "      <td id=\"T_67c50_row0_col7\" class=\"data row0 col7\" >0.000000</td>\n",
       "      <td id=\"T_67c50_row0_col8\" class=\"data row0 col8\" >0.000000</td>\n",
       "      <td id=\"T_67c50_row0_col9\" class=\"data row0 col9\" >1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_67c50_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_67c50_row1_col0\" class=\"data row1 col0\" >1.517610</td>\n",
       "      <td id=\"T_67c50_row1_col1\" class=\"data row1 col1\" >13.890000</td>\n",
       "      <td id=\"T_67c50_row1_col2\" class=\"data row1 col2\" >3.600000</td>\n",
       "      <td id=\"T_67c50_row1_col3\" class=\"data row1 col3\" >1.360000</td>\n",
       "      <td id=\"T_67c50_row1_col4\" class=\"data row1 col4\" >72.730000</td>\n",
       "      <td id=\"T_67c50_row1_col5\" class=\"data row1 col5\" >0.480000</td>\n",
       "      <td id=\"T_67c50_row1_col6\" class=\"data row1 col6\" >7.830000</td>\n",
       "      <td id=\"T_67c50_row1_col7\" class=\"data row1 col7\" >0.000000</td>\n",
       "      <td id=\"T_67c50_row1_col8\" class=\"data row1 col8\" >0.000000</td>\n",
       "      <td id=\"T_67c50_row1_col9\" class=\"data row1 col9\" >1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_67c50_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_67c50_row2_col0\" class=\"data row2 col0\" >1.516180</td>\n",
       "      <td id=\"T_67c50_row2_col1\" class=\"data row2 col1\" >13.530000</td>\n",
       "      <td id=\"T_67c50_row2_col2\" class=\"data row2 col2\" >3.550000</td>\n",
       "      <td id=\"T_67c50_row2_col3\" class=\"data row2 col3\" >1.540000</td>\n",
       "      <td id=\"T_67c50_row2_col4\" class=\"data row2 col4\" >72.990000</td>\n",
       "      <td id=\"T_67c50_row2_col5\" class=\"data row2 col5\" >0.390000</td>\n",
       "      <td id=\"T_67c50_row2_col6\" class=\"data row2 col6\" >7.780000</td>\n",
       "      <td id=\"T_67c50_row2_col7\" class=\"data row2 col7\" >0.000000</td>\n",
       "      <td id=\"T_67c50_row2_col8\" class=\"data row2 col8\" >0.000000</td>\n",
       "      <td id=\"T_67c50_row2_col9\" class=\"data row2 col9\" >1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_67c50_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_67c50_row3_col0\" class=\"data row3 col0\" >1.517660</td>\n",
       "      <td id=\"T_67c50_row3_col1\" class=\"data row3 col1\" >13.210000</td>\n",
       "      <td id=\"T_67c50_row3_col2\" class=\"data row3 col2\" >3.690000</td>\n",
       "      <td id=\"T_67c50_row3_col3\" class=\"data row3 col3\" >1.290000</td>\n",
       "      <td id=\"T_67c50_row3_col4\" class=\"data row3 col4\" >72.610000</td>\n",
       "      <td id=\"T_67c50_row3_col5\" class=\"data row3 col5\" >0.570000</td>\n",
       "      <td id=\"T_67c50_row3_col6\" class=\"data row3 col6\" >8.220000</td>\n",
       "      <td id=\"T_67c50_row3_col7\" class=\"data row3 col7\" >0.000000</td>\n",
       "      <td id=\"T_67c50_row3_col8\" class=\"data row3 col8\" >0.000000</td>\n",
       "      <td id=\"T_67c50_row3_col9\" class=\"data row3 col9\" >1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_67c50_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_67c50_row4_col0\" class=\"data row4 col0\" >1.517420</td>\n",
       "      <td id=\"T_67c50_row4_col1\" class=\"data row4 col1\" >13.270000</td>\n",
       "      <td id=\"T_67c50_row4_col2\" class=\"data row4 col2\" >3.620000</td>\n",
       "      <td id=\"T_67c50_row4_col3\" class=\"data row4 col3\" >1.240000</td>\n",
       "      <td id=\"T_67c50_row4_col4\" class=\"data row4 col4\" >73.080000</td>\n",
       "      <td id=\"T_67c50_row4_col5\" class=\"data row4 col5\" >0.550000</td>\n",
       "      <td id=\"T_67c50_row4_col6\" class=\"data row4 col6\" >8.070000</td>\n",
       "      <td id=\"T_67c50_row4_col7\" class=\"data row4 col7\" >0.000000</td>\n",
       "      <td id=\"T_67c50_row4_col8\" class=\"data row4 col8\" >0.000000</td>\n",
       "      <td id=\"T_67c50_row4_col9\" class=\"data row4 col9\" >1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x211cae11990>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os \n",
    "import pandas as pd\n",
    "\n",
    "os.listdir(path)\n",
    "data_path = os.path.join(path, 'glass.csv')\n",
    "\n",
    "df = pd.read_csv(data_path)\n",
    "df.head().style.background_gradient(cmap = 'Blues', axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3, 5, 6, 7], dtype=int64)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Type'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>RI</th>\n",
       "      <td>214.0</td>\n",
       "      <td>1.518365</td>\n",
       "      <td>0.003037</td>\n",
       "      <td>1.51115</td>\n",
       "      <td>1.516522</td>\n",
       "      <td>1.51768</td>\n",
       "      <td>1.519157</td>\n",
       "      <td>1.53393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Na</th>\n",
       "      <td>214.0</td>\n",
       "      <td>13.407850</td>\n",
       "      <td>0.816604</td>\n",
       "      <td>10.73000</td>\n",
       "      <td>12.907500</td>\n",
       "      <td>13.30000</td>\n",
       "      <td>13.825000</td>\n",
       "      <td>17.38000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mg</th>\n",
       "      <td>214.0</td>\n",
       "      <td>2.684533</td>\n",
       "      <td>1.442408</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>2.115000</td>\n",
       "      <td>3.48000</td>\n",
       "      <td>3.600000</td>\n",
       "      <td>4.49000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Al</th>\n",
       "      <td>214.0</td>\n",
       "      <td>1.444907</td>\n",
       "      <td>0.499270</td>\n",
       "      <td>0.29000</td>\n",
       "      <td>1.190000</td>\n",
       "      <td>1.36000</td>\n",
       "      <td>1.630000</td>\n",
       "      <td>3.50000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Si</th>\n",
       "      <td>214.0</td>\n",
       "      <td>72.650935</td>\n",
       "      <td>0.774546</td>\n",
       "      <td>69.81000</td>\n",
       "      <td>72.280000</td>\n",
       "      <td>72.79000</td>\n",
       "      <td>73.087500</td>\n",
       "      <td>75.41000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>K</th>\n",
       "      <td>214.0</td>\n",
       "      <td>0.497056</td>\n",
       "      <td>0.652192</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.122500</td>\n",
       "      <td>0.55500</td>\n",
       "      <td>0.610000</td>\n",
       "      <td>6.21000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ca</th>\n",
       "      <td>214.0</td>\n",
       "      <td>8.956963</td>\n",
       "      <td>1.423153</td>\n",
       "      <td>5.43000</td>\n",
       "      <td>8.240000</td>\n",
       "      <td>8.60000</td>\n",
       "      <td>9.172500</td>\n",
       "      <td>16.19000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ba</th>\n",
       "      <td>214.0</td>\n",
       "      <td>0.175047</td>\n",
       "      <td>0.497219</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.15000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fe</th>\n",
       "      <td>214.0</td>\n",
       "      <td>0.057009</td>\n",
       "      <td>0.097439</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.51000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Type</th>\n",
       "      <td>214.0</td>\n",
       "      <td>2.780374</td>\n",
       "      <td>2.103739</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.00000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>7.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      count       mean       std       min        25%       50%        75%  \\\n",
       "RI    214.0   1.518365  0.003037   1.51115   1.516522   1.51768   1.519157   \n",
       "Na    214.0  13.407850  0.816604  10.73000  12.907500  13.30000  13.825000   \n",
       "Mg    214.0   2.684533  1.442408   0.00000   2.115000   3.48000   3.600000   \n",
       "Al    214.0   1.444907  0.499270   0.29000   1.190000   1.36000   1.630000   \n",
       "Si    214.0  72.650935  0.774546  69.81000  72.280000  72.79000  73.087500   \n",
       "K     214.0   0.497056  0.652192   0.00000   0.122500   0.55500   0.610000   \n",
       "Ca    214.0   8.956963  1.423153   5.43000   8.240000   8.60000   9.172500   \n",
       "Ba    214.0   0.175047  0.497219   0.00000   0.000000   0.00000   0.000000   \n",
       "Fe    214.0   0.057009  0.097439   0.00000   0.000000   0.00000   0.100000   \n",
       "Type  214.0   2.780374  2.103739   1.00000   1.000000   2.00000   3.000000   \n",
       "\n",
       "           max  \n",
       "RI     1.53393  \n",
       "Na    17.38000  \n",
       "Mg     4.49000  \n",
       "Al     3.50000  \n",
       "Si    75.41000  \n",
       "K      6.21000  \n",
       "Ca    16.19000  \n",
       "Ba     3.15000  \n",
       "Fe     0.51000  \n",
       "Type   7.00000  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df.drop(columns='Type')\n",
    "y = df['Type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Feature Extraction with ANN + Classification with SVM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_in = (X_train.shape[1],)\n",
    "\n",
    "input_layer = tf.keras.Input(shape=d_in)\n",
    "x = tf.keras.layers.Dense(128, activation='relu', kernel_regularizer=\n",
    "                          tf.keras.regularizers.l2(0.01))(input_layer)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "x = tf.keras.layers.Dropout(0.5)(x)\n",
    "x = tf.keras.layers.Dense(64, activation='relu', kernel_regularizer=\n",
    "                          tf.keras.regularizers.l2(0.01))(x)\n",
    "output_layer = tf.keras.layers.Dense(X_train.shape[1])(x)\n",
    "model = tf.keras.Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-2), metrics=['accuracy'], loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,280</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">585</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m)              │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │         \u001b[38;5;34m1,280\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │           \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m8,256\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m)              │           \u001b[38;5;34m585\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">10,633</span> (41.54 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m10,633\u001b[0m (41.54 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">10,377</span> (40.54 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m10,377\u001b[0m (40.54 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> (1.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m256\u001b[0m (1.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 382ms/step - accuracy: 0.1489 - loss: 4.3415 - val_accuracy: 0.4000 - val_loss: 1.9281\n",
      "Epoch 2/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.5408 - loss: 2.5308 - val_accuracy: 0.2000 - val_loss: 1.8249\n",
      "Epoch 3/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.5028 - loss: 2.1095 - val_accuracy: 0.1667 - val_loss: 1.8197\n",
      "Epoch 4/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.3975 - loss: 1.8765 - val_accuracy: 0.1667 - val_loss: 1.8063\n",
      "Epoch 5/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.4808 - loss: 1.6476 - val_accuracy: 0.1667 - val_loss: 1.7723\n",
      "Epoch 6/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.4644 - loss: 1.6661 - val_accuracy: 0.2333 - val_loss: 1.7315\n",
      "Epoch 7/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.5412 - loss: 1.4097 - val_accuracy: 0.3000 - val_loss: 1.6950\n",
      "Epoch 8/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.5584 - loss: 1.3087 - val_accuracy: 0.3333 - val_loss: 1.6719\n",
      "Epoch 9/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.5797 - loss: 1.2439 - val_accuracy: 0.3667 - val_loss: 1.6539\n",
      "Epoch 10/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.5965 - loss: 1.1989 - val_accuracy: 0.3667 - val_loss: 1.6431\n",
      "Epoch 11/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.7198 - loss: 1.0493 - val_accuracy: 0.3333 - val_loss: 1.6212\n",
      "Epoch 12/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.6717 - loss: 1.0554 - val_accuracy: 0.3333 - val_loss: 1.5930\n",
      "Epoch 13/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.6381 - loss: 1.0090 - val_accuracy: 0.3333 - val_loss: 1.5624\n",
      "Epoch 14/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - accuracy: 0.7586 - loss: 0.9131 - val_accuracy: 0.3667 - val_loss: 1.5357\n",
      "Epoch 15/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.6930 - loss: 0.8643 - val_accuracy: 0.4333 - val_loss: 1.5043\n",
      "Epoch 16/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.6897 - loss: 0.8932 - val_accuracy: 0.4333 - val_loss: 1.4756\n",
      "Epoch 17/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.6893 - loss: 0.7870 - val_accuracy: 0.4333 - val_loss: 1.4524\n",
      "Epoch 18/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.7434 - loss: 0.7788 - val_accuracy: 0.4333 - val_loss: 1.4318\n",
      "Epoch 19/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.7013 - loss: 0.7367 - val_accuracy: 0.3333 - val_loss: 1.4088\n",
      "Epoch 20/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.7386 - loss: 0.7035 - val_accuracy: 0.3333 - val_loss: 1.3889\n",
      "Epoch 21/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.8030 - loss: 0.6592 - val_accuracy: 0.3333 - val_loss: 1.3681\n",
      "Epoch 22/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.7818 - loss: 0.6464 - val_accuracy: 0.3333 - val_loss: 1.3498\n",
      "Epoch 23/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.7658 - loss: 0.6062 - val_accuracy: 0.3333 - val_loss: 1.3267\n",
      "Epoch 24/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.7874 - loss: 0.5698 - val_accuracy: 0.3667 - val_loss: 1.2990\n",
      "Epoch 25/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.8090 - loss: 0.5578 - val_accuracy: 0.4000 - val_loss: 1.2739\n",
      "Epoch 26/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.8247 - loss: 0.5118 - val_accuracy: 0.4333 - val_loss: 1.2531\n",
      "Epoch 27/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.8090 - loss: 0.5459 - val_accuracy: 0.4000 - val_loss: 1.2321\n",
      "Epoch 28/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8083 - loss: 0.4790 - val_accuracy: 0.4000 - val_loss: 1.2169\n",
      "Epoch 29/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.7806 - loss: 0.4957 - val_accuracy: 0.3333 - val_loss: 1.2066\n",
      "Epoch 30/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.8199 - loss: 0.4353 - val_accuracy: 0.3333 - val_loss: 1.2082\n",
      "Epoch 31/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8131 - loss: 0.4191 - val_accuracy: 0.3667 - val_loss: 1.2035\n",
      "Epoch 32/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.7862 - loss: 0.4162 - val_accuracy: 0.4000 - val_loss: 1.1877\n",
      "Epoch 33/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.7650 - loss: 0.3960 - val_accuracy: 0.4000 - val_loss: 1.1684\n",
      "Epoch 34/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.7162 - loss: 0.3828 - val_accuracy: 0.4000 - val_loss: 1.1452\n",
      "Epoch 35/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.8679 - loss: 0.3700 - val_accuracy: 0.4000 - val_loss: 1.1215\n",
      "Epoch 36/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8575 - loss: 0.3839 - val_accuracy: 0.4000 - val_loss: 1.0955\n",
      "Epoch 37/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.8467 - loss: 0.3470 - val_accuracy: 0.4000 - val_loss: 1.0864\n",
      "Epoch 38/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.8094 - loss: 0.3352 - val_accuracy: 0.4000 - val_loss: 1.0769\n",
      "Epoch 39/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.7862 - loss: 0.3338 - val_accuracy: 0.4000 - val_loss: 1.0689\n",
      "Epoch 40/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.8150 - loss: 0.3125 - val_accuracy: 0.4333 - val_loss: 1.0667\n",
      "Epoch 41/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.8363 - loss: 0.3043 - val_accuracy: 0.4333 - val_loss: 1.0567\n",
      "Epoch 42/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.8903 - loss: 0.2996 - val_accuracy: 0.4667 - val_loss: 1.0472\n",
      "Epoch 43/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.8679 - loss: 0.2884 - val_accuracy: 0.4667 - val_loss: 1.0419\n",
      "Epoch 44/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.8627 - loss: 0.2596 - val_accuracy: 0.5333 - val_loss: 1.0353\n",
      "Epoch 45/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.8907 - loss: 0.2571 - val_accuracy: 0.5333 - val_loss: 1.0317\n",
      "Epoch 46/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8187 - loss: 0.2495 - val_accuracy: 0.5667 - val_loss: 1.0226\n",
      "Epoch 47/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.8687 - loss: 0.2363 - val_accuracy: 0.6000 - val_loss: 1.0113\n",
      "Epoch 48/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.8467 - loss: 0.2711 - val_accuracy: 0.6333 - val_loss: 1.0014\n",
      "Epoch 49/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.8307 - loss: 0.2333 - val_accuracy: 0.6000 - val_loss: 0.9912\n",
      "Epoch 50/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8691 - loss: 0.2465 - val_accuracy: 0.6000 - val_loss: 0.9834\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, X_train, epochs=50, batch_size=64, validation_split=0.2, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8033 - loss: 0.7634 \n",
      "Loss: 0.8500337600708008\n",
      "Accuracy: 0.7718120813369751\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(X_train, X_train)\n",
    "\n",
    "print(f'Loss: {loss}')\n",
    "print(f'Accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor shape=(None, 64), dtype=float32, sparse=False, name=keras_tensor_4>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[-2].output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_extractor = tf.keras.Model(inputs=model.input, outputs=model.layers[-2].output) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n"
     ]
    }
   ],
   "source": [
    "X_train_features = feature_extractor.predict(X_train)\n",
    "X_test_features = feature_extractor.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(C=1, gamma=1, probability=True)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(C=1, gamma=1, probability=True)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SVC(C=1, gamma=1, probability=True)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "svm = SVC(kernel='rbf', C=1, gamma=1, probability=True)\n",
    "svm.fit(X_train_features, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1.],\n",
       "       [0., 1., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 0., 1.],\n",
       "       [0., 1., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 1., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1.],\n",
       "       [1., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_prob = svm.predict_proba(X_test_features)\n",
    "y_prob.round()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.87      0.68      0.76        19\n",
      "           2       0.59      0.96      0.73        23\n",
      "           3       0.00      0.00      0.00         4\n",
      "           5       1.00      0.33      0.50         6\n",
      "           6       1.00      0.67      0.80         3\n",
      "           7       1.00      0.90      0.95        10\n",
      "\n",
      "    accuracy                           0.74        65\n",
      "   macro avg       0.74      0.59      0.62        65\n",
      "weighted avg       0.76      0.74      0.71        65\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\BM MONEY\\miniconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\BM MONEY\\miniconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\BM MONEY\\miniconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_pred = svm.predict(X_test_features)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7384615384615385"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_1 = accuracy_score(y_test, y_pred)\n",
    "acc_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[13,  6,  0,  0,  0,  0],\n",
       "       [ 1, 22,  0,  0,  0,  0],\n",
       "       [ 1,  3,  0,  0,  0,  0],\n",
       "       [ 0,  4,  0,  2,  0,  0],\n",
       "       [ 0,  1,  0,  0,  2,  0],\n",
       "       [ 0,  1,  0,  0,  0,  9]], dtype=int64)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. ANN Classification + SVM Refinement\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_encoded = tf.keras.utils.to_categorical(y_train - 1, num_classes=7)\n",
    "y_test_encoded = tf.keras.utils.to_categorical(y_test - 1, num_classes=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_in = X_train.shape[1]\n",
    "model2 = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(128, activation='relu',\n",
    "                          kernel_regularizer=tf.keras.regularizers.l2(0.01), input_dim=d_in),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dropout(0.25),\n",
    "    tf.keras.layers.Dense(64, activation='relu',\n",
    "                          kernel_regularizer=tf.keras.regularizers.l2(0.01)),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dropout(0.25),\n",
    "    tf.keras.layers.Dense(7, activation='softmax')\n",
    "])\n",
    "\n",
    "model2.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-2), \n",
    "               loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 460ms/step - accuracy: 0.1821 - loss: 3.4664 - val_accuracy: 0.5000 - val_loss: 2.6834\n",
      "Epoch 2/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.6393 - loss: 2.2970 - val_accuracy: 0.5333 - val_loss: 2.5057\n",
      "Epoch 3/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.7594 - loss: 1.8658 - val_accuracy: 0.6000 - val_loss: 2.3897\n",
      "Epoch 4/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.7702 - loss: 1.7419 - val_accuracy: 0.6000 - val_loss: 2.3010\n",
      "Epoch 5/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.7874 - loss: 1.6045 - val_accuracy: 0.5667 - val_loss: 2.2356\n",
      "Epoch 6/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.7930 - loss: 1.5311 - val_accuracy: 0.5000 - val_loss: 2.1918\n",
      "Epoch 7/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.7874 - loss: 1.4358 - val_accuracy: 0.5000 - val_loss: 2.1522\n",
      "Epoch 8/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.8030 - loss: 1.4309 - val_accuracy: 0.5000 - val_loss: 2.1126\n",
      "Epoch 9/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8355 - loss: 1.3094 - val_accuracy: 0.5000 - val_loss: 2.0671\n",
      "Epoch 10/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.8579 - loss: 1.2629 - val_accuracy: 0.5000 - val_loss: 2.0083\n",
      "Epoch 11/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.8687 - loss: 1.2102 - val_accuracy: 0.5000 - val_loss: 1.9563\n",
      "Epoch 12/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8255 - loss: 1.2020 - val_accuracy: 0.5000 - val_loss: 1.9276\n",
      "Epoch 13/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8791 - loss: 1.0721 - val_accuracy: 0.5333 - val_loss: 1.9019\n",
      "Epoch 14/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.8799 - loss: 1.0903 - val_accuracy: 0.5333 - val_loss: 1.8874\n",
      "Epoch 15/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.8627 - loss: 0.9990 - val_accuracy: 0.5000 - val_loss: 1.8627\n",
      "Epoch 16/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.8791 - loss: 0.8985 - val_accuracy: 0.5000 - val_loss: 1.8284\n",
      "Epoch 17/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.8415 - loss: 0.9339 - val_accuracy: 0.5000 - val_loss: 1.7866\n",
      "Epoch 18/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9127 - loss: 0.7747 - val_accuracy: 0.5000 - val_loss: 1.7548\n",
      "Epoch 19/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.8146 - loss: 0.8612 - val_accuracy: 0.5333 - val_loss: 1.7259\n",
      "Epoch 20/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.9336 - loss: 0.7628 - val_accuracy: 0.5000 - val_loss: 1.7050\n",
      "Epoch 21/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.8583 - loss: 0.7765 - val_accuracy: 0.5333 - val_loss: 1.6971\n",
      "Epoch 22/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.9119 - loss: 0.6700 - val_accuracy: 0.5000 - val_loss: 1.6824\n",
      "Epoch 23/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.8955 - loss: 0.6741 - val_accuracy: 0.5333 - val_loss: 1.6596\n",
      "Epoch 24/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.9015 - loss: 0.6495 - val_accuracy: 0.5667 - val_loss: 1.6529\n",
      "Epoch 25/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - accuracy: 0.8967 - loss: 0.6532 - val_accuracy: 0.5333 - val_loss: 1.6627\n",
      "Epoch 26/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.9127 - loss: 0.6495 - val_accuracy: 0.5333 - val_loss: 1.6773\n",
      "Epoch 27/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.8579 - loss: 0.6253 - val_accuracy: 0.6000 - val_loss: 1.6915\n",
      "Epoch 28/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.8751 - loss: 0.5877 - val_accuracy: 0.5000 - val_loss: 1.7109\n",
      "Epoch 29/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.9347 - loss: 0.5532 - val_accuracy: 0.4667 - val_loss: 1.7192\n",
      "Epoch 30/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.8851 - loss: 0.5610 - val_accuracy: 0.5000 - val_loss: 1.6979\n",
      "Epoch 31/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.9119 - loss: 0.5109 - val_accuracy: 0.4667 - val_loss: 1.6905\n",
      "Epoch 32/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.9123 - loss: 0.5291 - val_accuracy: 0.5000 - val_loss: 1.6828\n",
      "Epoch 33/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.8795 - loss: 0.5874 - val_accuracy: 0.4667 - val_loss: 1.6779\n",
      "Epoch 34/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.9067 - loss: 0.5104 - val_accuracy: 0.5000 - val_loss: 1.6675\n",
      "Epoch 35/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.8475 - loss: 0.6605 - val_accuracy: 0.5333 - val_loss: 1.6385\n",
      "Epoch 36/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.8907 - loss: 0.5765 - val_accuracy: 0.6000 - val_loss: 1.6192\n",
      "Epoch 37/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.8967 - loss: 0.5619 - val_accuracy: 0.5667 - val_loss: 1.6293\n",
      "Epoch 38/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9123 - loss: 0.4796 - val_accuracy: 0.5000 - val_loss: 1.6535\n",
      "Epoch 39/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.8855 - loss: 0.5442 - val_accuracy: 0.5000 - val_loss: 1.6817\n",
      "Epoch 40/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.8471 - loss: 0.5833 - val_accuracy: 0.4667 - val_loss: 1.6940\n",
      "Epoch 41/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.9287 - loss: 0.5268 - val_accuracy: 0.4333 - val_loss: 1.7194\n",
      "Epoch 42/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.8907 - loss: 0.4906 - val_accuracy: 0.4333 - val_loss: 1.7309\n",
      "Epoch 43/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9175 - loss: 0.4991 - val_accuracy: 0.3667 - val_loss: 1.7381\n",
      "Epoch 44/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.8795 - loss: 0.5739 - val_accuracy: 0.4000 - val_loss: 1.7411\n",
      "Epoch 45/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9011 - loss: 0.5331 - val_accuracy: 0.3333 - val_loss: 1.7489\n",
      "Epoch 46/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9291 - loss: 0.4388 - val_accuracy: 0.3333 - val_loss: 1.7490\n",
      "Epoch 47/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.8963 - loss: 0.5275 - val_accuracy: 0.4000 - val_loss: 1.7587\n",
      "Epoch 48/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.9504 - loss: 0.4581 - val_accuracy: 0.4000 - val_loss: 1.7811\n",
      "Epoch 49/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.9179 - loss: 0.4499 - val_accuracy: 0.3333 - val_loss: 1.8044\n",
      "Epoch 50/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.8743 - loss: 0.5013 - val_accuracy: 0.3000 - val_loss: 1.7941\n"
     ]
    }
   ],
   "source": [
    "history2 = model2.fit(X_train, y_train_encoded, epochs=50, batch_size=64, validation_split=0.2, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 509us/step - accuracy: 0.3565 - loss: 1.9102\n",
      "Loss: 2.177774667739868\n",
      "Accuracy: 0.3692307770252228\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model2.evaluate(X_test, y_test_encoded)\n",
    "\n",
    "print(f'Loss: {loss}')\n",
    "print(f'Accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred_proba = model2.predict(X_test)\n",
    "y_pred_ann= np.argmax(y_pred_proba, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.5\n",
    "uncertain_values = np.max(y_pred_proba, axis=1) < threshold\n",
    "certain_values = np.logical_not(uncertain_values)\n",
    "\n",
    "f_predictions = y_pred_ann.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_decoded = np.argmax(y_train_encoded, axis=1) + 1\n",
    "y_test_decoded = np.argmax(y_test_encoded, axis=1) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.00      0.00      0.00        19\n",
      "           2       0.67      0.43      0.53        23\n",
      "           3       0.00      0.00      0.00         4\n",
      "           4       0.00      0.00      0.00         0\n",
      "           5       1.00      0.33      0.50         6\n",
      "           6       0.67      0.67      0.67         3\n",
      "           7       1.00      0.90      0.95        10\n",
      "\n",
      "    accuracy                           0.35        65\n",
      "   macro avg       0.42      0.29      0.33        65\n",
      "weighted avg       0.51      0.35      0.41        65\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\BM MONEY\\miniconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\BM MONEY\\miniconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\BM MONEY\\miniconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\BM MONEY\\miniconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\BM MONEY\\miniconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\BM MONEY\\miniconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "svm2 = SVC(kernel='rbf' ,C=1, probability=True)\n",
    "svm2.fit(X_train, y_train_decoded)\n",
    "\n",
    "if np.sum(uncertain_values) > 0:\n",
    "    f_predictions[uncertain_values] = svm2.predict(X_test[uncertain_values])\n",
    "\n",
    "print(classification_report(y_test_decoded, f_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.35384615384615387"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_2 = accuracy_score(y_test, f_predictions)\n",
    "acc_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [18,  0,  1,  0,  0,  0,  0,  0],\n",
       "       [11,  2, 10,  0,  0,  0,  0,  0],\n",
       "       [ 3,  0,  1,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  3,  0,  1,  2,  0,  0],\n",
       "       [ 1,  0,  0,  0,  0,  0,  2,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  1,  9]], dtype=int64)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conf = confusion_matrix(y_test, f_predictions)\n",
    "conf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy Processing 1 and 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7384615384615385, 0.35384615384615387)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_1, acc_2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
